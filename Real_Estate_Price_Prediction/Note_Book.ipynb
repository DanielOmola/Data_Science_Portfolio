{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################\n",
    "#\n",
    "#  much of the cod is stored in \n",
    "#  my package for more readability\n",
    "#\n",
    "# ##################################\n",
    "#from mypackage import ploter_bis as plt_bis\n",
    "from mypackage import ploter\n",
    "from mypackage import data_processor as dp\n",
    "from mypackage import mydataloader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "print(tscv)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data\n",
    "    \n",
    "# ########## Chose the periode\n",
    "\n",
    "#years = [2020,2019,2018,2017,2016,2015,2014]\n",
    "#years = [2020]\n",
    "years = [2020,2019,2018,2017]\n",
    "\n",
    "\n",
    "# ########## Chose the area with departement code\n",
    "\n",
    "#departements = ['75'] \n",
    "departements = ['75','92','93','94','77','78','91','95'] \n",
    "departements = ['75','92','93','94','95']\n",
    "\n",
    "\n",
    "data = dl.get_market_data(years = years,departements=departements,top_cities=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Features engineering with special encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = dp.feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Helper function for Model Selection\n",
    "> Based on Time Series Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(models,X,y,verbose=True):\n",
    "    i=1\n",
    "    model_score = []\n",
    "    for name,model in models.items():\n",
    "        scores = cross_val_score(model, X,y, cv=tscv)\n",
    "        if verbose:\n",
    "            print(f\"{name} | score : {scores.sum()/5}\")\n",
    "        model_score.append((scores.sum()/5,model))\n",
    "        i+=1\n",
    "    best_model = sorted(model_score, reverse=True)[0][1]\n",
    "    print('\\n######## Best Model ########\\n\\t%s'%str(best_model))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "ridge = linear_model.Ridge(alpha=.1)\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "bayesian_ridge = linear_model.BayesianRidge()\n",
    "svr = svm.SVR() # >== scale very badly\n",
    "rf = RandomForestRegressor(max_depth=10,min_samples_leaf=10, random_state=0)\n",
    "gbreg = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Cross validation with Initial Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'OLS regression' : ols,\n",
    "          'Ridge regression' : ridge,\n",
    "          'Lasso regression' : lasso,\n",
    "          'Bayesian Ridge regression' : bayesian_ridge\n",
    "          }\n",
    "\n",
    "\n",
    "features_basic = ['surface','pieces','terrain']\n",
    "\n",
    "model = model_selection(models,X_train[features_basic],y_train)\n",
    "\n",
    "model.fit(X_train[features_basic],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploter.check_model_performances(X_train[features_basic],y_train,model,show=True)\n",
    "ploter.check_model_performances(X_test[features_basic],y_test,model,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - Cross validation with Encoded Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {'OLS regression' : ols,\n",
    "          'Ridge regression' : ridge,\n",
    "          'Lasso regression' : lasso,\n",
    "          'Bayesian Ridge regression' : bayesian_ridge,\n",
    "          'RandomForestRegressor' : rf,\n",
    "          'Gradient Boosting Regressor':gbreg\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 - Cross validation with 'encodage_voie' as a single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_augmented = ['encodage_voie']\n",
    "\n",
    "\n",
    "model = model_selection(models,X_train[features_augmented],y_train)\n",
    "model.fit(X_train[features_augmented],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploter.check_model_performances(X_train[features_augmented],y_train,model,show=True)\n",
    "ploter.check_model_performances(X_test[features_augmented],y_test,model,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 - Cross validation with all encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_augmented = ['surface','pieces','encodage_voie','encodage_piece',\n",
    "                     'encodage_type_voie','encodage_ville','encodage_departement',\n",
    "                      'terrain','id_local']\n",
    "\n",
    "model = model_selection(models,X_train[features_augmented],y_train)\n",
    "model.fit(X_train[features_augmented],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploter.check_model_performances(X_train[features_augmented],y_train,model,show=True)\n",
    "ploter.check_model_performances(X_test[features_augmented],y_test,model,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 - Cross validation with 5 encoded features\n",
    "#### These features will be used for ease of future model deployment.\n",
    "* surface\n",
    "* pieces\n",
    "* encodage_voie\n",
    "* terrain\n",
    "* id_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_augmented = ['surface','pieces','encodage_voie',\n",
    "                      'terrain','id_local']\n",
    "\n",
    "model = model_selection(models,X_train[features_augmented],y_train)\n",
    "model.fit(X_train[features_augmented],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=features_augmented)\n",
    "except :    \n",
    "    feat_importances = pd.Series(model.coef_, index=features_augmented)\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = X_train[features_augmented]\n",
    "D['y'] = y_train\n",
    "\n",
    "sns.pairplot(D,vars=D.columns[:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### not working with docker and my configuration\n",
    "\n",
    "#dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Investigate errors on Train Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_info = X_train[['Commune','surface','pieces']]\n",
    "predictions_train = model.predict(X_train[features_augmented])\n",
    "\n",
    "final_predictions_train = pd.concat([train_info.reset_index(),y_train.reset_index().drop(columns=['index']),pd.Series(predictions_train.reshape(-1))],axis=1)\\\n",
    ".drop(columns='index')\n",
    "\n",
    "\n",
    "final_predictions_train.columns = ['commune','surface','pieces','target','pred']\n",
    "\n",
    "final_predictions_train[['target','pred']] = np.exp(final_predictions_train[['target','pred']])\n",
    "\n",
    "final_predictions_train['error'] = abs(final_predictions_train.target-final_predictions_train.pred)\n",
    "\n",
    "final_predictions_train.sort_values(by=['error'],ascending=False).tail(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D = final_predictions_train\n",
    "D['y'] = y_train\n",
    "\n",
    "#sns.pairplot(D,vars=D.columns[:-1], hue=\"y\")\n",
    "sns.pairplot(D,vars=D.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Mean error by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_city = final_predictions_train.groupby(['commune'])\\\n",
    "                       .agg({'error':['min','mean','max','std']})\\\n",
    "                       .reset_index()\n",
    "\n",
    "errors_city.columns=['commune','error_min','error_mean','error_max','std_error']\n",
    "errors_city=errors_city.sort_values(by=['error_mean'])\n",
    "errors_city['inv_error_mean']=errors_city['error_mean'].apply(lambda v : 1/v)\n",
    "errors_city['inv_std_error']=errors_city['std_error'].apply(lambda v : 1/v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 - City with high mean errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_city[['commune','error_mean']].tail(10)\n",
    "ploter.show_cloud(errors_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 - City with low mean errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_city[['commune','error_mean']].head(10)\n",
    "ploter.show_cloud(errors_city,'inv_error_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 -  Standard deviation of error by City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 - City with high std errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploter.show_cloud(errors_city.dropna(),'std_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 - City with low std errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ploter.show_cloud(errors_city.dropna(),'inv_std_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The DVF dataset is useful for predicting future prices, as long as proper data preprocessing is applied.\n",
    "* The encoding technique I applied definitely improves the performance on the Test set, even with a single encoded data. Nonetheless, the model is overfiting.\n",
    "* Grid search should be applied to help improve model performance. But I didn't cover this part because the best model could change, depending on the area selected. \n",
    "* Adding features specific to each home (the condition and practicality of the property) should help improve the model predictive power.\n",
    "* The more we move away from Paris the less the model makes errors.\n",
    "* It seems like the dynamic of the real estate market of Paris and nearby suburbs differs from that of distant suburbs. This needs to be investigated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Next step : Model deployment with Flask, Docker..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
